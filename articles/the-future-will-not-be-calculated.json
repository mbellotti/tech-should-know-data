{
"title": "The Future Will Not Be Calculated: Neural Nets, Neoliberalism, and Reactionary Politics",
"authors": [
"Orit Halpern"
],
"abstract": "<p><span>This article traces the relationship between neoliberal thought and neural networks through the work of Friedrich Hayek, Donald O. Hebb, and Frank Rosenblatt. For all three, networked systems could accomplish acts of evolution, change, and learning impossible for individual neurons or subjects—minds, machines, and economies could therefore all autonomously evolve and adapt without government. These three figures, I argue, were also symptoms of a broader reconceptualization of reason, decision making, and “freedom” in relation to the state and technology that occurred throughout the 1950s–1970s. I also argue that this genealogy of decision-making underpins contemporary relations between machine learning, reactionary politics, and neoliberal economics.</span></p>",
"content": "<p>In 1945, the economist <mark id=\"inline-0\" class=\"inlineNote\">Friedrich Hayek</mark> began his battle on behalf of neoliberalism with a call to rethink knowledge. In an essay that looms large over the history of contemporary conservative and libertarian economic thought, Hayek inaugurated a new concept of the market:</p><blockquote><p>The peculiar character of the problem of a rational economic order is determined precisely by the fact that the knowledge of the circumstances of which we must make use never exists in concentrated or integrated form, but solely as the dispersed bits of incomplete and frequently contradictory knowledge which all the separate individuals possess. The economic problem of society is thus not merely a problem of how to allocate “given” resources—<em>if “given” is taken to mean given to a single mind which deliberately solves the problem set by these “data.”</em> It is rather a problem of how to secure the best use of resources known to any of the members of society, for ends whose relative importance only these individuals know. Or, to put it briefly, it is a problem of the utilization of knowledge not given to anyone in its totality.1</p></blockquote><p>This was no small claim. When situated within the broader context of Hayek’s engagements with the sciences and technologies of the time, this seemingly theoretical statement gestures to a grand aspiration: a fervent dream for a new world governed by “data.” At the heart of Hayek’s conception of a market was the idea that no single subject, mind, or central authority has complete knowledge of the world. He argued that “the ‘data’ from which the economic calculus starts are never for the whole society ‘given’ to a single mind … and can never be so given” (“UK,” p. 519). <mark id=\"inline-1\" class=\"inlineNote\">Only markets can learn at scale and suitably evolve to coordinate dispersed resources and information in the best way possible.</mark></p><p>Such proposals might appear at first as unintuitive responses to political catastrophe. Hayek was a fierce critic of both fascism and communism. His argument concerning the uses of knowledge was in direct response to what he viewed as a violent political crisis created by democratic populism. His response, unlike that of many other cultural critics of the time, was not, however, to buffer the support for a reasonable liberal human subject but rather to imagine the replacement of human reason through distributed intelligence and the technology of the market.</p><p>This emerging neoliberal imaginary did not operate in isolation. As historians of science have noted, Cold War rationality did not conform to the dictates of Enlightenment reason. The specter of technologically induced planetary destruction through nuclear war, and the memory of global war created a critique of human decision-making. This critique fostered the production of a formal, repeatable, and algorithmic model of decision-making, one that perhaps mirrored the emerging new computer technologies of the time.2</p><p>But if the rational decision maker was still an expert in area studies or science, the intelligence Hayek proposed, I argue, was somewhat different. The rational technocrat was capable of objectivity, planning, and predicting futures; the subjective and ignorant figure Hayek provides us with was not.</p><p>Almost simultaneously, and in conversation with economists, psychologists and technologists also began proposing a new model of the mind as distributed, stochiastic, and environmental. Psychologists, for example, working with wounded and injured soldiers and traumatized animals, found that brains could rewire themselves. Psychiatrists working between analytic logic and computing began asking about the possibility that neurons might operate like logic gates, making autonomous decisions that only retroactively were networked into cognition or perception.</p><p>To make this argument I will trace the reformulation of intelligence through the links between the work of the Canadian neuroscientist <mark id=\"inline-2\" class=\"inlineNote\">Donald O. Hebb</mark>, the Austrian economist and neoliberal Hayek, and the American psychologist and artificial intelligence forerunner Frank Rosenblatt. Hebb’s experiments with injured brains demonstrated the possibility of neuroplasticity and created a model of neural nets. Hayek developed theories of distributed decision-making in markets and minds. And for Rosenblatt, networked neurons could learn from pooling populations of data. For all three, networked systems could accomplish acts of evolution, change, and learning impossible for individual neurons or subjects—minds, machines, and economies could therefore become self-governing, able to change and deal with the unexpected through their own internally grounded properties of emergence and self-organization. These three figures, I argue, were also symptomatic of a broader reconceptualization of reason, decision-making, and “freedom” in relation to the state and technology that occurred throughout the 1950s–1970s.</p><p>This map provides one glimpse into the broader genealogy of contemporary machine learning in relationship to politics and economy. In her foundational formulation of neoliberal history, Naomi Klein posed the “shock” therapies of Hebb and his successor Donald Ewen Cameron, psychiatrists in the early 1950s, as metaphors or allegories for neoliberal capitalism.3 Extending this observation, I want to examine the history binding psychology to economics and now to computing. I argue that neural-network research and shock therapies are not merely metaphors of neoliberal policies but forms of knowledge and practice that anticipated our contemporary forms of artificial intelligence and governmentality.</p><p>However, while all these figures hoped to replace older questions of representation, freedom, and data collection with a fantasy of self-organizing and emergent information systems, historical notions of agency, cognition, and modelling continued to haunt the new discourse of probability, nets, and self-organization. For example, psychological experiments with sensory deprivation and torture proved that the dynamic instability of networks can also have catastrophic effects. Shock—whether through sensory deprivation, misinformation, noise, or sensory overload—could all lead to mental and systemic failures, often to paranoia and delusions. These experiments mirrored within individuals what many sociologists and theorists of the time diagnosed as the “paranoid style” in American politics.4 For neoliberals, the conspiratorial and paranoic style of populist democratic politics, associated with fascism and communism, didn’t support “free” markets. But those very markets themselves posed the constant threat of turning to irrational speculation.5</p><p>The question that emerged was how to make brains, and perhaps societies, resilient to extreme volatility and what might be labelled, for humans, trauma. <mark id=\"inline-3\" class=\"inlineNote\">The response, on one hand, was to reconceive trauma as a question of information circulation <em>and</em> as an opportunity for networks to “learn.”</mark> On the other hand, there was born an aspiration to perhaps surpass politics by way of redistributing and even automating decision-making and responsibility.</p><h2><strong>Minds</strong></h2><p>The Second World War definitively consolidated a new conception of human cognition. Throughout the postwar period the idea that human minds and machine logic might be modelled upon the same assumptions became a core bedrock of the emergent computer and communication sciences. Such ideas were most famously popularized through Norbert Wiener’s <em>Cybernetics</em>, which introduced the sciences of “control and communication in the animal and the machine.”6 <mark id=\"inline-4\" class=\"inlineNote\">Cybernetics</mark> paralleled the behavior of biological organisms with that of the calculations of logical machines.7</p><p>Emerging from wartime research invested in predicting human and machine behavior (the trajectories of fighter planes, the best way to bomb populations, the movements of enemy armies), it is not surprising that the management of the future figured as the central concern. The world, however, was in Wiener’s words “Bergsonian”—full of probabilities and entropic forces that were difficult to control and predict and, worse yet, hardly causal or intentional.8 Put another way, the future was difficult to represent. Logic, however, upon which most programming was grounded at the time, was a causal, linear, finite, and representable form of calculation. The function of the new science of cybernetics would therefore be to bridge this seeming incommensurability between logic and probability in order to contain chance.</p><p>While this might appear a Sisyphean task, in the psychology of the time this conflict inspired new models of the brain and cognition. The idea that brains might possess the capacity to simultaneously be stochastic—possessing self-organizing cybernetic properties, while also capable of logical functions—caught hold. If symbolic programming could not produce problem solving machines, perhaps there were other forms of machines that might be able to work “as we may think.”9 Of the many new models of machine minds to appear at the time, perhaps none looms as large over our present moment than that of Hebbian synapses.</p><p>In 1949, Hebb announced this new concept of the mind. “It is … impossible,” he wrote, “that the consequence of a sensory event should often be uninfluenced by the pre-existent activity [of the neurons]… . The problem for psychology is no longer to account for the existence of set but to find out how it acts and above all to learn how it has the property of consistent, selective action.”10 Neurons, Hebb argued, are not static relays of data, merely completing stimulus-response reactions. Rather, he forwarded a stochastic understanding of the brain and intelligence. When synapses fired in concert this increased the probability of cognition. In neuroscience, and later machine learning, the finding was summarized as: “Cells [that is, neurons] that fire together, wire together.”11</p><p>Hebb was among many to ponder the dynamic mechanics of the brain. In 1943, the McCulloch-Pitts model of the neural net was introduced, and Hebb apparently was influenced by this research and cybernetics. The neural net was perhaps the first logical demonstration of how neurons could theoretically (at least) physically compute logical problems; proving that psychic processes could emerge from physiology. The model was an enormous reduction from real neurons, but it inspired a new concept of minds as both mechanic and programmable.12</p><p>These ideas of cognition emerged from within a context in which psychologists were both treating victims of war and contending with postwar critiques of eugenics and biological racism. Hebb was working with individuals who had suffered injuries to the brain: a problem that was of increasing concern during and after the Second World War. In his research he documented how different cognitive functions might return over time even though parts of their brains were injured. Victims of stroke and accidents all appeared capable, over time, of regaining functions initially lost with the injury. Hebb even found that often cognitive skills and new modes of action could be learned by the injured subject, and he assumed this was the result of the neurons finding new connections circumventing the injury. Correlating these observations with studies of neurons, electroencephalogram (EEGs), and other rather theoretical and imperfect (by our standards) efforts to visualize neuronal action, Hebb concluded that networks of neurons are capable of learning by reorganization. Cognition, he concluded, was networked, and neurons assembled in certain arrangements might be capable of functioning in ways that were unanticipatable from their discrete biology or location. <mark id=\"inline-5\" class=\"inlineNote\">Hebb intended his work as an attack on psychological testing, particularly the racist Binet IQ tests, and the concept that people stored specific pieces of discrete unrelated data and that individuals could not be taught or trained</mark>.13 He concluded his pathbreaking work: “The country may be full of potential geniuses, for all we know, and it should be a pressing concern for psychology to discover the conditions that will develop whatever potentialities a child may have” (<em>O</em>, p. 303). His research responded to both genetic determinism and behaviorism.</p><h2><strong>Synaptic Memory</strong></h2><p>The ability for brains to seemingly reorganize their networks to recover also inspired Hebb’s theory of memory and storage. Hebb elaborated that these networks, today called Hebbian synapses, were syncopated in time and could be trained: “Let us assume that the persistence or repetition of a reverberatory activity (or “trace”) tends to induce lasting cellular changes that add to its stability… . <em>When an axon of cell</em> A <em>is near enough to excite a cell</em> B <em>and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that</em> A<em>’s efficiency, as one of the cells firing</em> B, <em>is increased</em>” (<em>O</em>, p. 62). The model posited that neurons that fire in temporal relationships to one another (syncopated although not synchronous) strengthen their relationship—the more they repeat the action, the stronger the net. Neuronal nets are thus weighted statistically. The more often they fire together, the more likely they will do so in the future; they are learning. Brains thus do more than just their individual neurons because there is a temporal feature to the net, one of statistical training.</p><p>This model suggested that what was stored in a brain—the content of perceptions, memories, and cognitive commands—was not the result of an infinite database of stored information (this was not a theory of the infinite archive of the Freudian unconscious) but rather was comprised of patterns, or <em>nets</em> of relations between neurons. The archive was one of patterns, not of stimuli. Certain stimuli would trigger networked pathways that collaboratively created an action of thought or behavior. One did not store every image of a dog for example but rather stored a pattern that would trigger upon the stimulus of a dog. Brains store a process or an architecture, not specific pieces of data.</p><p>Hebb makes a leap here, grounded in gestalt and other psychologies with great bearing in the history of computing. Mainly, he argues that while the <em>structure</em> of the brain appears the same, memory is the result of experience and traces: “This suggests that the mnemonic trace, the neural change that is induced by experience and constitutes ‘memory,’ is not a change of structure” (<em>O</em>, p. 12). That is to say, the neurons are there materially, and there is a biological substrate to learning, but it is not deterministic. Such ideas also suggest that the same structure might be capable of multiple different functions.</p><p>Such structural understandings did not preclude the idea of distributed cognition within the brain. In Hebb’s later work with animals in the Yerkes Lab at Yale, extending from his earlier dissertation research with Karl Lashley at Harvard, he would discover that environment played a key role in transforming the training and conditioning of intelligence, even after injury.14 As Hebb would argue, extrapolating from Lashley’s research, “memory traces are not localized in the cerebral cortex … [rather] the trace is structural but diffuse, involving, that is, a large number of cells widely spaced in the cortex, physiologically but not anatomically unified” (<em>O</em>, p. 13). This, he reasoned, was not evidence against structure but simply evidence for diffused structures that operated in concert.</p><h2><strong>Neuroplasticity</strong></h2><p>The corollary of this theory of neuroplasticity is that our environments retime our neurons and change memory, cognition, and perception. Brains were imagined to be networked architectures, capable of being trained and their nets resyncopated. Thus, even with physiological changes to the brain (such as an accident) the model posited that neurons would rewire and create new statistical relations, allowing a new net of coactivating neurons to emerge. The brain could learn and change at a physiological, neuronal, scale while still maintaining its biological integrity.</p><p>Brains, but also people, were therefore not stable but dynamic and probabilistic entities. Hebb supposed that the brain was more than its neurons. The same physiological structures could reconnect in different patterns in time and produce a variety absolutely unanticipatable from a mere map of the brain. Biology could be accounted for but without determinism. We might argue that this brain shared with the systems theories of the mid-twentieth century a faith in <em>emergence</em>, the unexpected recombination of existing elements to produce the new, as a fundamental property of cognition and evolution.15</p><p>Hebb’s research firmly reconfigured notions of cognition as ecological (the result of interactions between individuals and their environments), thus turning psychological attention to the environment as a medium for therapy or conditioning, and fundamentally transformed understandings of memory and minds as networked and storing populations of patterns or nets rather than discrete data points. In isolation, none of these points appear that important, but collectively, and in conversation with similar innovations in economics and computer science, we might trace the emergence of a new imaginary of both neurons and markets.</p><h2><strong>Markets</strong></h2><p>These ideas of a self-organizing, and perhaps even evolving, intelligence soon found close bedfellows with economists also concerned with how systems recover from failures and trauma (in this case those of the Depression and the subsequent world war). Economics had long been grounded in the concept of <em>the invisible hand</em>; but older histories of the market continued to rely on the fantasy of an omniscient reasonable decision maker. Now a new discourse had emerged by which to also reimagine the economic agent.16</p><p>In the preface of his often overlooked <em>The Sensory Order</em>, Hayek wrote:</p><blockquote><p>Professor D. O. Hebb’s <em>Organization of Behavior</em> … contains a theory of sensation which in many respects is similar to the one expounded here; and in view of the much greater technical competence I doubted … whether the publication of the present book was still justified … as I am concerned more with the general significance of a theory of that kind than with its detail, the two books, I hope, are complementary rather than covering the same ground.17</p></blockquote><p>Hayek claimed this relation on the grounds that he felt that there might be a different utility of Hebb’s theory, not for reprogramming individual psyches, but for modelling emerging self-organizing phenomena.</p><p><em>The Sensory Order</em> was Hayek’s most complete foray into a theory of mind and psychology. While clearly invoking cybernetics and contemporary scientists, the book must also be regarded within the broader context of Hayek’s economic and political thought. Hayek accentuated this relation by making great efforts to emphasize the congruence between his newest philosophy of mind and his previous work. <em>The Sensory Order</em> according to Hayek’s introduction was based on a manuscript that he had originally prepared in 1920, despite being published in a revised version in 1952. What had changed, Hayek emphasized, was his investment in the newly founded sciences of cybernetics and the new models of psychology, which provided him ample inspiration concerning the governance of both individuals and markets—and more critically a bridge between the two. Inspired by the work of Wiener, Hayek proposed an idea that markets and minds might both work as cybernetic machine processes, without consciousness or plan.18</p><h2><strong>Maps and Models</strong></h2><p>Hayek’s model of mind and the brain rested on the limits to human knowledge and, by extension, the limits of conscious decision-making. The framing question in Hayek’s theory of mind was why we perceive the world through our senses differently than how science describes the world.19 He questioned “[how we] know the kind of process by which a given physical situation is transformed into a certain phenomenal picture” (<em>SO</em>, p. 7). As Steven Horwitz notes, Hayek’s model of the mind was comprised of two evolutionary processes.20 The first process was that of species adaptation. The physical structure of the mind had evolved to process sensorial data in a manner that created shared perceptions amongst all human beings. The second process involved individual adaptation; each person obviously develops their own forms of perception and neural linkages through life experience and environmental influence. Hayek was a <em>materialist</em> because he believed that there was a physical architecture of the brain that conditioned perception. However, he departed from any faith that material structure <em>determined</em> the full cognitive ability of the mind. Minds were more than their parts. To argue this, the economist turned to Hebb and to notions of self-organization (see <em>SO</em>).21</p><p>Hayek negotiated this relation between materiality and emergence through a fundamental reconstruction of Hebbian theories using the figures of the “map” and the “model.” The map refers to the neural networks that the brain builds from lived experience. It is the corollary of the Hebbian synapse, “What we have before called the ‘map’, the semi-permanent apparatus of classification, provides the different generic elements from which the models of particular situations are built” (<em>SO</em>, p. 130). Maps are the connections that can be hooked up to produce models.</p><p>Hayek imagined a “feedback” loop between these two processes—maps and models.22 This situation offers the capacity for “successful adaptation” in two ways: “It selects some elements from a complex environment as relevant for the prediction of events which are important for the persistence of the structure, and it treats them as instances of classes of events” (<em>SO</em>, p. 131). In this conception, as in Hebb, what is stored in the mind, and potentially in human institutions, is an archive of “classes of events.” Hayek, by way of Hebb, thus argued that cognition is comprised of these maps whose nature is hardly territorial or spatial but is rather unstable, dynamic, and always open to reorganization. Maps tie individuals to populations through models.</p><h2><strong>Discrimination and Distinction</strong></h2><p>This paradigm posits cognition as the direct result of physiological processes that manifest in a temporal neural order. “The phenomena,” Hayek wrote,</p><blockquote><p>with which we are here concerned are commonly discussed in psychology under the heading of ‘discrimination’. This term is somewhat misleading because it suggests a sort of ‘recognition’ of physical differences between the events which it discriminates, while we are concerned with a process which <em>creates</em> the distinctions in question. The same is true of most of the other available words which might be used, such as ‘to sort out’, ‘to differentiate’, or ‘to classify.’</p><p>[<em>SO</em>, p. 48]</p></blockquote><p>For Hayek the world is not comprised of clearly discriminating things nor of <em>recognizable</em> entities. <mark id=\"inline-6\" class=\"inlineNote\">Rather it is a world of processing, whose goal is to produce discrimination and recognition, or <em>distinctions</em>.</mark></p><p>This concept of perception emerging through the timing of processes mapped on to Hayek’s broader logic, one that always understood the market as an environmental construct that organized both materials and human thoughts and desires. What is key in this statement is that perception is a process that <em>creates distinctions</em>; <mark id=\"inline-7\" class=\"inlineNote\">the world therefore is not full of preexisting or already known objects and subjects.</mark> To recognize, but also to discriminate, is a <em>process</em> for human beings, one that Hayek insists cannot be known by one subject. As a process, perception also unfolds in time. This temporality leant mind a self-organizational property, which denoted that human cognition could not be reduced to its material basis. Minds like markets could never be fully calculated, even as their physical and environmental conditioning makes individual cognition subjective and limited.</p><h2><strong>Archives of Indeterminacy</strong></h2><p>By deduction, we might also understand the brain, and perhaps by extension the state, as functioning as a “repository” or archive of these apparatuses of classification or models for construction. States thus serve only the function of being an archival repository of processes or classes upon which the market (or mind) may operate in the present and imagine the future.</p><p>This is an idea that Hayek favored:</p><blockquote><p>It is the contention [of the true individualist tradition] that, by tracing the combined effects of individual actions, we discover that many of the institutions on which human achievements rest have arisen and <em>are functioning without a designing and directing mind</em> … and that the <em>spontaneous</em> collaboration of free men often creates things which are greater than their individual minds can ever fully comprehend.23</p></blockquote><p><mark id=\"inline-8\" class=\"inlineNote\">In this account, human institutions are not designed; they emerge as the result of accumulating processes over time.</mark> From this perspective, the Hebbian inspired physiological account of learning as a process of forging neurological connections also explains why individuals had to be bound together through the population-level institution of the market. As in models of networked minds, decision-making is decentralized. There is a noncausal and stochiastic relationship between individual actions and the whole of the market (systems amount to more than a sum of their parts, and this <em>more</em> is subject to chance). Markets and human minds had spontaneous, emergent properties that made them resistant to socialized planning; but each needed the other to work.24</p><p>Therefore, institutions such as markets can manage population scale data and communicate knowledge in efficient ways—that is, only the market can bring together “limited individual fields of vision” and hence enable economic problems to be <em>solved</em> (“UK,” p. 526). The plastic and networked mind was thus the critical figure and analog to begin the process of creating markets that could be datafied and self-organizing but never representable in their completion.25</p><h2><strong>Freedom and Democracy</strong></h2><p>When situated in relationship to Hayek’s ideal of the economy as the most and perhaps only route to human freedom, we can trace the rise of a broader ideology that identified the flow of information and its coordination as the necessary infrastructure for human freedom, liberty, and equality (all terms he used interchangeably).26 For Hayek, freedom from coercion was the only freedom that could be called “liberty,” and coercion equated with “all attempts to impose upon a society a deliberately chosen pattern of distribution”; from this, we can deduce that any forced effort to produce particular populations or data distributions (for example, forcing integration or reallocating wealth to different populations by plan) would mean, for Hayek, a challenge to human liberty and freedom.27 It is possible to read Hayek, though, as allowing for the possibility that redistributing wealth, or health care, might be necessary conditions to enable individuals to exercise noncoerced choices in the market (what might be labelled <em>freedom</em>). Neoliberal discourse, on the other hand, focused on asserting the seemingly natural, and never calculatable, nature of market processes; thus rendering any form of preplanning or redistribution of resources or services as endangering the very possibility of evolution and by derivation terminating the possibility of any future other than the present.28 This tension would come to play out critically in fantasies that envisioned feedback and the increasing flow of data as possible solutions to these impasses in democratic political orders.</p><h2><strong>Cybernetic Liberties</strong></h2><p>While Hayek initially deferred from making direct analogies between minds and markets, by the late 1970s he began to erode this distinction. In fact, throughout the period of his later work, Hayek, in tandem with many other social scientists of the era, would call more and more on cybernetics and systems biology as bulwarks to justify his stance on <em>freedom</em> and price theories. In 1977 he presented his long neglected psychological theories paralleling human and economic systems, arguing:</p><blockquote><p>In both cases we have complex phenomena in which there is a need for a method of utilizing widely dispersed knowledge. The essential point is <em>that each member (neuron, or buyer, or seller)</em> is induced to do what in the total circumstances benefits the system. Each member can be used to serve needs of which he doesn’t know anything at all. Now that means that in the larger (say, economic) order, knowledge is utilized that is not planned or centralized or <em>even conscious</em>… . In our whole system of actions, we are individually steered by local information—information about more facts than any other person or authority can possibly possess. And <em>the price and market system is in that sense a system of communication</em>, which passes on (in the form of prices, determined only on the competitive market) the available information that each individual needs to act, and to act rationally.29</p></blockquote><p>Hayek’s account captured the idea that intelligence is networked—whether composed of neurons or human individuals—and that it consists in the capability of populations to adapt to their environment by reorganization. More critically, he argues that increasingly the ideal of a democratic or free order takes on the formation of a networked intelligence operating purposefully, but not necessarily consciously, through the model of a communication system, for which price is one type. Such ideals of organization underpinned a growing conception of systems as self-evolving and emergent, capable of novelty and innovation and adaptation (if competitive, of course) without any forms of deliberative or representative decision-making.</p><p>As others have noted, Hayek faced increasing challenges to his theories as the democratic collapse neoliberals had imagined happening in the UK and US after the war never occurred. To support the ideology of free markets as a route to freedom, Hayek increasingly turned to theories of systems and emergence in biology and cybernetics. These models offered a concept of systems as capable of purposeful evolution without direction and created a language by which to imagine systems whose capacity for change and adaptation would come through internal mechanisms of feedback and reflexivity rather than political oversight and the state.30</p><p>When viewed within the context of Hayek’s life work, the revolutions in his thought are manifold. First, Hayek posits that markets are about coordinating information, not matching supply and demand—a critical first step, as historians such as Philip Mirowski have noted, towards contemporary notions of information economies.31 Second, Hayek’s model of learning and <em>using knowledge</em> is grounded in the idea of a networked intelligence embodied in the market. Markets can allow the creation of knowledge outside of and beyond the purview of individual humans. “The whole acts as one market, not because any of its members survey the whole field, but because their limited individual fields of vision sufficiently overlap so that through many intermediaries the relevant information is communicated to all (“UK,” p. 526). <mark id=\"inline-9\" class=\"inlineNote\">The market therefore embodies a new form of <em>environmental</em> intelligence—which is to say a notion of cognition and decision-making dispersed into the world and possessed by entities outside of the human.</mark> The data upon which such a calculating machine operates is dispersed throughout the society, making decision-making a population grounded activity derived from but not congruent with individual bodies and thoughts.</p><h2><strong>Machines</strong></h2><p>The market, Milton Friedman once said, is “an ‘engine’ to analyze [the world], not a photographic reproduction of it.’”32 But if it is an engine, what form of machine would it be? In 1956, a series of computer scientists, psychologists, and related scientists embarked on a new version of cybernetics. In a proposal for a workshop at Dartmouth College in 1955, they termed this new concept <em>artificial intelligence</em>. The title was not defined, and <mark id=\"inline-10\" class=\"inlineNote\">that choice of terms was arguably the result of demands for military funding.</mark> While numerous approaches were made, one key marker of early efforts to create this intelligence was the interest in a machine’s ability to “build up within itself an abstract model of the environment in which it is placed … and then attempt external experiments.” Through these experiments such a machine might learn and even be “imaginative.”33 Such a notion of intelligence is predicated on not merely pattern seeking but also model building or learning.</p><p>Consider Frank Rosenblatt’s concept of the “perceptron.”34 Rosenblatt proposed that learning itself—whether in nonhuman animals, humans, or computers—could be modeled on artificial, cognitive devices that implement the basic architecture of the human brain. The goal of Rosenblatt’s research, like that of many cybernetically inspired psychologists of the time, including Hebb and McCulloch, was to develop models that a computer could run that might test or experiment with how brains might work. <mark id=\"inline-11\" class=\"inlineNote\">His intent was therefore not so much to build computers but to build models that might advance the understanding of human brains.</mark> The perceptron was supposed to be a machine to produce ideas about minds—a task that he in fact completed on an IBM 704 computer at the Cornell Aeronautical Laboratory in 1957.35</p><p>In his initial paper detailing the idea for the perceptron, that emerged from the 1956 program, <mark id=\"inline-12\" class=\"inlineNote\">surprisingly Rosenblatt distances himself from his other artificial-intelligence forerunners like Warren McCulloch, Marvin Minsky, and Ross Ashby</mark>. This separation was grounded in terms of determinism and representation. These scientists had been “chiefly concerned with the question of how such functions as perception and recall might be achieved by a deterministic physical system of any sort, rather than how this is actually done by the brain.”36 This approach, he argued, was lacking. It fundamentally ignored the question of scale and the emergent properties of biological systems. Rosenblatt himself believed that a mere refinement of principles suggested by these theorists would therefore never account for biological intelligence—instead, he set his hopes in the theory of statistical separability, which, he wrote, “has been heavily influenced by Hebb and Hayek.”37</p><p>What is key here is that Rosenblatt insists that the combination of neural nets might offer possibilities for learning that individual isolated logic gate/neurons might not. Rosenblatt emphasized that within this model, learning was not a matter of comparing external stimuli to internal models or patterns but rather described the process of establishing new associations among the elements of the neural net. The perceptron produced a concept of intelligence that inhered in probability and suggested that learning could be formulated as a statistical process. Crucially, Rosenblatt’s model depended upon a net of neuron-like entities among which associations would be established whenever a sensory organ was triggered by external stimuli (see “P”). Whereas earlier models of the neural net and cybernetic intelligence insisted upon the idea of singular and isolated individuals, this model fundamentally rested upon the assumption that intelligence must emerge from the actions of multiple agents and not merely isolated machines.</p><p>A central tenet of his approach is that neurons are mere switches or nodes in a network that classifies cognitive input—intelligence emerges only on the level of the population and through the patterns of interaction between neurons. The key to learning for the neural net approach was exposure to a “large sample of stimuli,” so that those stimuli that “are most ‘similar’ … will tend to form pathways to the same sets of responding cells” (“P,” pp. 388, 388–89). As Rosenblatt stressed, this meant approaching the nature of learning <mark id=\"inline-13\" class=\"inlineNote\">“in terms of probability theory rather than symbolic logic”</mark> (“P,” p. 388).</p><p>The perceptron manifested the significance of independent, cognitive entities in the process of learning yet, at the same time, abstracted from the biology or nature of these elements and posited that they do not need to be conscious. It first put the model present in Hebb’s psychological experiments to work and promised to provide simulations of the dynamics of populations of neurons.</p><p>As Robert Mitchell notes, it is precisely because perceptrons require training data (as well as an <em>agent</em> who helps the neural net assess the training data) that they can in principle be trained on population-level experience.38 Though each human individual is limited to a specific set of external stimuli to which he or she is in fact exposed, a computer perceptron can, by contrast, draw on data that are the result of judgements and experiences of not just one individual but rather large populations of human individuals. Rosenblatt elaborated on this point by arguing that the perceptron was a model of learning for which “the properties of the components may be fully specified, but the organization of the network is specified only in part, by constraints and <em>probability distributions which generate a class of systems</em> rather than a specific design.”39</p><p>In other words, for Rosenblatt, the goal of brain modeling was not to construct a specific representational diagram for a specific task but rather to identify the rules by which neurons interact efficiently to classify the world. The perceptron both captured the idea that cognition and intelligence derive from the rule-based interactions of neurons and suggested that cognition could be modelled by means of a set of algorithms. These rules execute themselves, however, through the small actions of individual decision-making units that are networked together. This assemblage can produce more sophisticated decisions, much like the Hayekian market can coordinate many small decisions to self-organize and act in more complex ways. Intelligence here is reformulated as networked and capable of evolution through population level coordination of data.</p><p>I emphasize the notion of evolution and probability in the thought of both economists and technologists because for both such notions of learning forwarded ideas that systems might change and adapt nonconsciously. The central feature of these models concerned evading the need to represent the solution of a problem or the future. The model posits that small operations done on small parts of a problem might agglomerate as a group into more than their parts and solve problems whose solutions do not require represention to the machine ahead of time. In this, both Hayek and Rosenblatt take from theories of communication and information, particularly from cybernetics that posit communication in terms of thermodynamics. Systems at different scales are probabilistically related to their parts. Calculating each individual component will not predict the act of the entire system. The hope is that these small operations might culminate in producing more sophisticated “thoughts” while evading the problem of actually having to describe or represent the solution.40 While not truly possible, this contradictory need to evade representation, continues to fuel our desire for unsupervised learning in nets and the agglomeration of ever larger data sets. The data would, in theory, drive the thought.</p><p>Hebb, Hayek, and Rosenblatt thus serve as historical figures offering evidence of a seismic change in the history of intelligence and the conception of agency and decision-making. However, previous conceptions of psychology and ideas of liberal subjectivity haunted the new machines that they had conceived.</p><h2><strong>Entropy</strong></h2><p><mark id=\"inline-14\" class=\"inlineNote\">The very feature that made such systems evolutionary and emergent, were also their terminal point of failure.</mark> The stochastic property of nets lent to unpredictability and potentially increases in entropy (noise). Such concerns were long running in the cybernetic sciences. Wiener had long warned that we live in a world of demons and that these monsters of probability made fate difficult to control.41 The cybernetics sciences were but small efforts at order in a world of excess data and complexity beyond the analytic scope of our machines.42</p><p>On a less metaphysical level, neural-network researchers and theoreticians found two remaining and inseparable problems, both related to the integrity of the subject and the residual problem of perception: one concerned excess data, and the second concerned adaptability or plasticity. If human brains could be trained, how did human beings maintain their stability in the face of environmental stresses? How did nets know if they are being trained on errors? Or manipulated? In short, how do you know if a signal is coming from without or within the net and from when? And if a system is always adapting, how does it not mutate to the point of extinction or psychosis?</p><p>Early in his work, Hebb remarked that the “stability” of learning was sometimes maladjusted to “perception” (see <em>O</em>)—thereby begging the question of how a net maintains its training and not constantly change in accordance with new data. This was later called the sensitivity-stability problem. Systems that were too sensitive to new inputs became unstable and lose stability of “meaning” (<em>O</em>, p. 15). Rosenblatt also discovered that errors in weighting might propagate and exacerbate errors, and positive feedback might lead to oscillation and instability—much of the perceptron model is dedicated to correction of errors including through back propagation. Neural network researchers only refracted a broader discourse repeated by cyberneticians, political scientists, social scientists, and economists—<mark id=\"inline-15\" class=\"inlineNote\">What if networked feedback loops fed the wrong positive feedback (for example in nuclear confrontations) leading to network instability (and, by proxy, social ) and even terminal failure?</mark>43</p><p>In the postwar period, economists also obsessed about how to avoid the sort of market failures (or shocks) that had led to the rise of totalitarian regimes in Europe after the First World War. Within the context of the Cold War such historical memories of market failure came adjoined with new concerns about the future survival of democratic and capitalist societies.44</p><p>The question, however, was about decision-making. Were populations sound decision makers? A history of populist democratic fascism or rabid anticommunism might suggest otherwise. Richard Hofstadter’s pathbreaking analysis of Senator McCarthy’s anticommunism stands out in this regard. This “paranoid style,” he argued, understands the world in terms of patterns of behavior among different targeted groups, overstating the possibility of prediction and control of the future. In short, too much data might also provide ecological fallacies and false patterns.45 Today such conspiracy theories are derided as reactionary politics.</p><p>However, such paranoias provoked problems for the concept of the <em>invisible hand</em>. Economists, like technocrats, had to provide new concepts of decision-making that might evade the determinism of conspiracy but still legitimate the purported democracy of the market. As Alfred Moore has noted, while Hayek never directly discussed “conspiracy” and rarely paranoia, the economist played</p><blockquote><p>an important yet ambivalent [role] in the development of [anti-conspiratorial] political epistemology. Although he doesn’t use the term “conspiracy theory,” he sets his entire theoretical project against conceiving complex orders as though they were designed or planned, and he seeks always to show how <mark id=\"inline-16\" class=\"inlineNote\">patterned orders that <em>look</em> like they must have been designed in fact arose through anonymous and unwitting processes of emergence and evolution.</mark></p><p>[“H,” p. 48]</p></blockquote><p>Hayek’s obsession was thus modelling the world as one of self-organizing adaptive systems to counter the idea of planned and perfectly controllable political (in his mind totalitarian) orders.</p><h2><strong>Noise</strong></h2><p>What we might find surprising, however, is how this seeming terminal problem became a newfound capacity in nets and markets. In his now infamous sensory deprivation study, Hebb unearthed this volatile nature of neural nets. The study was funded by the Canadian Defense Research Board. While this research has gained infamy as the progenitor of soft torture in the CIA, its initial goal was far more banal. It was to examine the “monotony” of contemporary work environments and their impact on attention. Radar operators and other people working in the newly electronic workspace were known to suffer extreme “boredom,” inattention, and depression.46 To test the monotony of the modern work environment, twenty-two male student volunteers were recruited to lie in a chamber designed to induce “‘perceptual isolation.’”47 The experimental theory correlated the increase of electronic data with sensory deprivation.48 In other words, boredom and information overload were assumed to be implicitly related—which is to say that too much data given in certain environments might be the same as no data at all. Sensory deprivation could therefore also exist in a very noisy environment.</p><p>To ensure maximum “boredom,” the students wore a translucent plastic visor that emitted diffuse light to prevent “pattern” vision, as well as cotton gloves and cardboard cuffs that covered their arms from elbow to fingertips to eliminate or at least reduce tactile stimulation.49 A U-shaped foam rubber pillow helped dampen auditory stimuli, and, according to reports, a constantly running air conditioner masked small sounds. Intermittently the participants were given verbal and written tests for cognitive acuity and memory and were also made to listen to a battery of recordings with counter-scientific, supernatural, and superstitious propaganda. Afterwards, individuals were examined for their attitudes towards supernatural phenomena, and their responses were compared to those made before the experiment. Individuals hallucinated and suffered impaired cognitive functioning. By the end, many participants seemed to believe in ghosts and the supernatural, and no one lasted in the space for more than four days. The study appeared to demonstrate how thinking could be impacted without the subjects’ bodies ever being touched.50 When adjoined to theories of networked cognition and neuroplasticity, it appeared that brains could be remotely programmed, from afar, through suggestion and environmental manipulation of data. Hebb himself labelled it “torture,” an observation that found concrete realization in the CIA’s Cold War interrogations.51</p><p>As the funding sources and reasons for the studies demonstrated, Hebbian notions of networked cognition were also a new way to know the world and a new epistemology for an information economy. These studies began as a way to understand what the new excesses of data and homogeneity of electronic media might do to the mind, while also creating a new understanding of cognition as scalable, enhanceable, and programmable. After the study, debates have raged over whether participants suffered from too little or too much data (the sounds and stimulus of the containment are also forms of stimulus potentially). For psychologists and an army of trainers after Hebb, information overload increasingly became a norm and an expectation. Following Hebb’s lead, researchers such as John Lilly began investigating the virtues of sensory deprivation. Perhaps, psychologists postulated, such environments might help individuals train their attentions to meet the demands and channel out the constant noise of contemporary mediated societies. Today, we might note the rise of training regimens for the shocks of contemporary life aimed at teaching the subject to concentrate and manage and filter excess data (now called stress) such as yoga, immersion tanks, self-care, and apps for sleep, concentration, and mindfulness, all of which supposedly arose from Hebb’s research. What had been torture was increasingly understood as the very condition of contemporary, electronically mediated life. And learning to manage that pain became the essence of survival, preferably through conditioning attention and the senses.52</p><p>Shock—whether through sensory deprivation, fake data, inaccurate information, viruses, noise, or sensory overload—was reconceived not as uniquely traumatic but as unavoidable. Psychologists were not alone in this discovery. In economics as well, since the 1970s, flash crashes, noise trading, and exponentially leveraged positions have been core concerns but also opportunities in markets, now understood as arbitrators of information. Financiers and economists increasingly built models that assumed the world was full of noise and that in fact it increasingly was the role of reason to operate at a constant and adaptive level upon it.53</p><p>At the height of the introduction of algorithmic trading and derivative instruments to the market, computer-scientist-turned-financial-guru Fischer Black, one of the creators of the derivatives market, wrote:</p><blockquote><p>The effects of noise on the world, and on our views of the world, are profound. Noise in the sense of a large number of small events is often a causal factor much more powerful than a small number of large events can be. Noise makes trading in financial markets possible, and thus allows us to observe prices for financial assets.54</p></blockquote><p><mark id=\"inline-17\" class=\"inlineNote\">Black’s “Noise” formalized a new discourse in finance and posited that we trade and profit from misinformation and information overload.</mark>55 By the 1980s these ideas of networked, stochastic, and population-based intelligences had transformed into technologies, as embodied by the Black-Scholes option pricing model, to manage individuals, labor, and finance.</p><p>In this new embrace of automated financial trading, what no longer existed was the problem of equilibrium or a concern for entropic disorganization. While nineteenth- and earlier twentieth-century economists, including Hayek, worried about the maintenance of the market itself and of the stability of value—and about entropy and the tendency of systems, whether political or economic, to degrade—now that concern has been deferred and even capitalized upon. Options trading makes volatility and speculation, an excess of information in the market, a site of extracting value.56 Ominously, we might recall Hayek’s original statements that perception is a process dedicated to producing “distinctions” or “discrimination[s]”; we might now say that in financial capital those very constant differentiations have become the infrastructure for speculation.</p><p>Hayek himself espoused an imaginary about this data rich world that could be increasingly calculated without (human) consciousness. He was arguably very fond of quoting Alfred North Whitehead’s remark that “it is a profoundly erroneous truism … that we should cultivate the habit of thinking what we are doing. The precise opposite is the case. <mark id=\"inline-18\" class=\"inlineNote\">Civilization advances by extending the number of important operations we can perform without thinking about them</mark>” (quoted in “H,” p. 50).57 The perceptron, widely held to be the forerunner of contemporary deep learning with nets, is the technological manifestation of a more widespread reconfiguration and reorganization of human subjectivity, physiology, psychology, and economy. And there is a curious and conflicting hope that technical decision-making made at the scale of populations, not through governments, might ameliorate the danger of populism or the errors of human judgement. The net became an idea and a technique to be able to scale from within the mind to the planetary networks of electronic trading platforms and global markets.</p><p>What I am stressing in making these correlations is how these new ideas about decision-making through populations of neurons reformulated economic, psychological, and computational practices and experimental methods. In doing so, the ideal of networked intelligence became the dominant ideology that made machine learning and economic decision-making commensurate and part of the same system. Moreover, computation came to be seen as environmental: a milieux that should be extended into every mode of social and political life and a site for producing value.</p><p>Ironically, however, the very problems of false patterns, delusions, and noise that threatened the stability of such a self-organizing system were the grounds for an increased demand to introduce more computation into the environment. Rather than safeguard networks by perhaps fostering different types of systems—the state separated from the economy or psychology separated from computation—these crises in fact drove for the increased assimilation of more territory into calculation. More data, maybe even noise, was the answer. The less that enters consciousness, the more operations that can be made without thought, the better.</p><h2><strong>Dreams for Our Perceptual Present</strong></h2><p>With great implications for our present, Hayek argued that the democratic spirit introduced “a new unwillingness to submit to any rule or necessary the rationale of which man does not understand.” As Moore puts it: “This, we might say, is one effect of the expansion of the franchise, and of the Enlightenment demand to submit to authority only when one can make its reasons one’s own reasons. A demanding standard”—and a destructive one for the economy in this formulation (“H,” p. 52). Hayek echoed the fears of many liberals in the postwar period by arguing that in complex societies individuals are unable to singularly grasp the reasons why things are happening to them, whether unemployment or bad health, or any other life event. Unable to grasp complexity—perhaps, we might say, unable to contend with a surfeit of data or with noisy environments—democratic subjects become psychotic and paranoid, amenable to conspiracy and blame their distress on others. Hayek already had this “environmental conception of conspiracy” (“H,” p. 52).</p><p>It is perhaps an irony of history that the answer to this problem of overinundation and data surplus appeared to be a turn to cybernetics, new models of networked cognition, and ultimately perhaps even a new model of machine learning that might indeed learn from the distributed intelligence of millions, and now billions, of people. At the same time, such technologies make it impossible to encounter the very legitimate sources of pain in contemporary societies whether induced by structural racism, poverty, disease, or environmental degradation.</p><p>This returns us to our present. If Hayek and Hebb still worried about liberal subjects and objectivity, we might ask what concerns animate our contemporary networks? Markets, and now reactionary politics, seek instability and discrimination but without diversity. Shock has been normalized to be managed through our electronic networks. Networks appear to have the power to exacerbate fantasies of individual control and paranoid imaginaries of agential patterns. <mark id=\"inline-19\" class=\"inlineNote\">If “shock” for Klein was a mechanism to destabilize systems and nations to allow the entry of neoliberal governance, we might extend her observation to recognize that now it has become a tool to maintain existing neoliberal systems and to encourage the growth and proliferation of machine learning networks and algorithmic finance.</mark>58</p><p>I opened this article by arguing that cybernetics and its affiliated communication and human sciences aspired to the elimination of political and psychological trauma through a dream of self-organizing systems and autopoietic intelligences produced from the minute actions of small, stupid, logic gates, a dream of a world of networks without limit, focused eternally on an indefinite and extendable but never-defined future that might be consumed in the present. This dream may now be partially realized, and we have to generate a new set of fantasies.</p><p>To do so does not, however, mean wishing, like reactionary politicians, to return to a mythic past. It does not denote fantasizing a Cartesian ethics with transparent algorithms and no black boxes. To do so would only be to replicate the reactionary logic of the database, where processes of distinction and inevitably discrimination are stored only to be retrieved without consciousness or history.</p><p>Nor does it mean evading the power we have bequeathed from our machines. The apparatus of the epistemology of the neural net has opened to both positive potentials—neurodiversity, plasticity, and new forms of collectivity—even as it has enhanced the financialization of life and the necropolitics of neoliberal economics. As Randy Martin has argued, rather than separating itself from social processes of production and reproduction, algorithmic finance demonstrates the increased interrelatedness, globalization, and socialization of debt and precarity. By tying together disparate actions and objects into a single assembled bundle of reallocated risks to trade, the new market machines make us more indebted both to each other. The political and ethical question thus becomes how we might activate this increased indebtedness in new ways, ones that are less amenable to the strict market logics of neoliberal economics.59</p><p>Hayek, himself, gestured to this possibility within his own thought. Markets he argued, demand difference: “From the fact that people are very different it follows that, <mark id=\"inline-20\" class=\"inlineNote\">if we treat them equally, the result must be inequality in their actual position, and that the only way to place them in an equal position would be to treat them differently.</mark> Equality before the law and material equality are therefore not only different but are in conflict with each other; and we can achieve either the one or the other, but not both at the same time.”60 With these words he stated the fundamental dilemma of neoliberalism: to be free we must be put in relation to each other. But he also wavers: Does liberty denote equal treatment, and therefore a generic law, or differential and situated treatment, which might denote planning or coercion? The response of neoliberal discourse has been to automate this relation, thus obscuring its social character, and extract value from the differences between humans while maintaining that such relations emerge evolutionarily and thus are nonintentional but natural and necessary.</p><p>Might this discourse be disrupted? Recalling the argument that difference is the foundation for freedom or liberty, can we push this neoliberal imaginary until it folds? This tension might be the source of a possible freedom through relations, if they are historically situated. The fantasy of an archive of processes of differentiation might be mobilized to new ends—mainly to recognizing the permeable, political, and situated nature of social orders. The future, I argue, lies in recognizing what our machines have finally made visible, what has perhaps always been there, mainly the sociopolitical nature of our seemingly natural thoughts and perceptions. In that all computer systems are programmed, and therefore planned, we are also forced to contend with the intentional and therefore changeable nature of how we both think and perceive our world.</p>",
"submissionBy": {
"name": "Marianne Bellotti",
"link": "www.bellotti.tech"
},
"notes": [
{
"id": "0",
"text": "A Nobel prize winner and something of a mentor to Milton Friedman and the rest of the Chicago School, Hayek claimed to have predicted the Great Depression. His most significant work is <em>The Road to Serfdom</em> which criticizes government control of the economy and puts him solidly on the right anti-Communist/Socialist-skeptical side of the political spectrum. Halpern is most interested in Hayek's theories on spontaneous order, in which the market contains complex networks of information and dynamic process that determine its direction rather than hard and fast rules or conscious decision making."
},
{
"id": "1",
"text": "I love Halpern's work because she approaches conversations about technology from the perspective of media studies and history, rather than engineering. I find her writing quite heady, but her argument is essentially that trends in political philosophy shape the assumptions we make about what problems technology can solve and how to structure or iterate on our approaches to building technology. If you can handle the academic prose, her books are worth the deep dive. Especially considering unlike other selections here she is likely to produce a whole lot more."
},
{
"id": "2",
"text": "Hebb is best known for the maxim \"Neurons that fire together wire together\" (Hebb's Law) based on his theory that nerves that excite each other grow progressively closer together. Learning, therefore, represents an ever-changing algorithm shaped by the feedback loop of the brain responding to stimuli."
},
{
"id": "3",
"text": "This is kind of the dark side of the culture of blameless postmortems. There is something dehumanizing about seeing all negative outcomes as an opportunity for learning. The argument here is if you completely remove the emotion from the system model, you end up with a callous and exploitative society endlessly trying to distill things down to \"data\" in order to \"learn\" how to be righteous. You can see this in the AI community's current obsession with \"alignment\" (learn human values through additional training) over ergonomics and human factors."
},
{
"id": "4",
"text": "Cybernetics shares the same root word with Kubernetes, referring to steering, a helmsman of pilot. While during Wiener's time Cybernetics was a poorly fleshed out discipline that gathered what we would consider wildly different scientific activities--today it is popping up more and more in computer science as our progressively connected and networked lives make explorations of control systems and feedback loops more and more relevant."
},
{
"id": "5",
"text": "The irony being that Hebb once respected the advocate of such tests--Robert Yerkes--so much he wrote him personally and was offered a position studying under him at Yale."
},
{
"id": "6",
"text": "The point being, two objects can be the same or different depending on which criteria are most relevant at the time. Apples and oranges are both fruit in one sense, but only one has edible skin. Halpern does a deeper analysis of Hayek in <em>The Smartness Mandate</em>: the world is full of infinite variation (even two oranges will have differences in size, color, etc) therefore our sense of sameness and <strong>difference</strong> are both learned behaviors developed by aggregation of available data (for contrast) and the relevant context that data applies to."
},
{
"id": "7",
"text": "Failure to understand this concept cripples a lot of AI product design as people expect the key criteria to train and detect is self-evident for the machine."
},
{
"id": "8",
"text": "Decades of Harvard Business Review back issues scream into the void..."
},
{
"id": "9",
"text": "Typically when people think about collective decision making, it's the \"wisdom of crowds\" model in which judgment errors are thought to be outliers and rational decision found in the average of many people's singular choice in one decision topic. This is a different model of collective decision making, in which we zoom out and look at the long term outcomes and accomplishments of a population--a decision made up of hundreds or thousands of individual decisions executed without knowledge of each other."
},
{
"id": "10",
"text": "A surprising amount of our world is shaped by marketing trends and fads in the defense space."
},
{
"id": "11",
"text": "There's a razor thin distinction here: neural networks were not about building a computer brain but about building an insightful model of the human brain with computers. In a sense the shift in emphasis from model of to artificial version of is the equivalent of suggesting a flight simulator pilot your next commercial flight."
},
{
"id": "12",
"text": "I'm not sure this is too surprising. Between Minsky predicting they were 3~8 years away from artificial general intelligence in Life magazine in 1970 to McCulloch predicting the extinction of the human race ... it's the overpromise, underdeliver club."
},
{
"id": "13",
"text": "Personally I think that the next era of advancement in AI will blend both strategies rather than pick between them."
},
{
"id": "14",
"text": "One of our most critical misunderstandings in comparing humans to machines by \"error\" rates. Some portion of human error is a byproduct of the same processing that fuels creativity, adaptation, and our best, most insightful problem solving."
},
{
"id": "15",
"text": "Perhaps part of the problem is that we make our artificial networks larger and larger, whereas biological populations segment networks. Instability of learning is mitigated by the fact that individuals within a population have some isolation from each other (we can't read each other's minds) so bad learning results in individual death which removes said learning from the collective intelligence (and reenforces awareness of the mistake in survivors)"
},
{
"id": "16",
"text": ".... otherwise known as \"No, Facebook is not listening to you through your mobile phone to show you ads about products you mention\""
},
{
"id": "17",
"text": "Halpern goes into much more detail about Black and the connection she is drawing to network intelligence here in her book The Smartness Mandate. Essentially the gist of it is that financial markets rely on the market's inability to price assets the way traditional economics claims they should be able to. If markets were able to price things correctly, there would be few options to \"buy low and sell high\" because price fluctuations would be rare. Black-Scholes acknowledged this principle and controlled for variation by leveraging variation."
},
{
"id": "18",
"text": "Largely a product of well developed abstractions and axioms"
},
{
"id": "19",
"text": "I feel there's a larger, not yet fully developed, point lingering the in the background here for Halpern. Sensory deprivation techniques that were once torture are now used as self-care in a digital world overwhelming us with stimulus. Shock tactics once used to destabilize systems are now a tool to preserve a very extreme status quo..."
},
{
"id": "20",
"text": "Even for Hayek, full libertarianism was a bridge too far. Full equality was often counterproductive to the goal of liberty and one had to decide which one was more important. Hayek had rather complex views on affirmative action, for example, he thought <em>private</em> institutions should be free to discriminate but public ones should not. I think this comes down to the private institution being a market transaction and the presumption that the market would punish decisions made based on inappropriate criteria. Whereas a public institution is immune from market forces."
}
],
"references": [],
"works": [
{
"link_title": "Original Paper",
"link_url": "https://www.journals.uchicago.edu/doi/full/10.1086/717313"
}
],
"tags": [
"neural network",
"cognitive science",
"cybernetics",
"economics",
"artificial intellgience"
]
}